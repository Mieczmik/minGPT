{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23370501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e6543f",
   "metadata": {},
   "source": [
    "# Embedding - czyli zamienianie s≈Ç√≥w na wektory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fc603d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Life is short, eat dessert first'\n",
    "\n",
    "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
    "print(dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37ee04c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 5, 2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "sentence_int = torch.tensor([dc[s] for s in sentence.replace(',', '').split()])\n",
    "print(sentence_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8416c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "embed = torch.nn.Embedding(6, 16)\n",
    "embedded_sentence = embed(sentence_int).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be293cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
      "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
      "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
      "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
      "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
      "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
      "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
      "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
      "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
      "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
      "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
      "torch.Size([6, 16])\n"
     ]
    }
   ],
   "source": [
    "print(embedded_sentence)\n",
    "print(embedded_sentence.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb420c2",
   "metadata": {},
   "source": [
    "# Macierze wag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72df421",
   "metadata": {},
   "source": [
    "Teraz om√≥wmy szeroko stosowany mechanizm samo-uwagi znany jako **scaled dot-product attention**, kt√≥ry stanowi integralny element architektury transformera.\n",
    "\n",
    "Mechanizm samo-uwagi wykorzystuje trzy macierze wag: **W<sub>q</sub>**, **W<sub>k</sub>** oraz **W<sub>v</sub>**, kt√≥re sƒÖ dostrajane jako parametry modelu podczas uczenia.  \n",
    "Macierze te s≈Çu≈ºƒÖ do rzutowania wektor√≥w wej≈õciowych na odpowiednie reprezentacje: **zapytania (query)**, **klucze (key)** i **warto≈õci (value)**.\n",
    "\n",
    "Odpowiednie sekwencje zapyta≈Ñ, kluczy i warto≈õci otrzymuje siƒô przez mno≈ºenie macierzy wag **W** przez wektory osadze≈Ñ wej≈õciowych **x**:\n",
    "\n",
    "- **Sekwencja zapyta≈Ñ:**  \n",
    "  $$\n",
    "  \\mathbf{q}^{(i)} = \\mathbf{W}_q \\mathbf{x}^{(i)} \\quad \\text{dla } i \\in [1, T]\n",
    "  $$\n",
    "\n",
    "- **Sekwencja kluczy:**  \n",
    "  $$\n",
    "  \\mathbf{k}^{(i)} = \\mathbf{W}_k \\mathbf{x}^{(i)} \\quad \\text{dla } i \\in [1, T]\n",
    "  $$\n",
    "\n",
    "- **Sekwencja warto≈õci:**  \n",
    "  $$\n",
    "  \\mathbf{v}^{(i)} = \\mathbf{W}_v \\mathbf{x}^{(i)} \\quad \\text{dla } i \\in [1, T]\n",
    "  $$\n",
    "\n",
    "Indeks *i* odnosi siƒô do pozycji tokena w sekwencji wej≈õciowej, kt√≥rej d≈Çugo≈õƒá wynosi *T*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b458f2",
   "metadata": {},
   "source": [
    "Zar√≥wno **q<sup>(i)</sup>**, jak i **k<sup>(i)</sup>** sƒÖ wektorami o wymiarze *d‚Çñ*. Macierze projekcji **W<sub>q</sub>** oraz **W<sub>k</sub>** majƒÖ rozmiar $d_k \\times d$, natomiast macierz **W<sub>v</sub>** ma rozmiar $d_v \\times d$. Warto zauwa≈ºyƒá, ≈ºe *d* reprezentuje rozmiar ka≈ºdego wektora s≈Çowa *x*. Poniewa≈º podczas obliczania iloczynu skalarnego miƒôdzy wektorami zapyta≈Ñ i kluczy wymagane jest, aby te dwa wektory mia≈Çy tƒô samƒÖ liczbƒô element√≥w ($d_q = d_k$), liczba element√≥w w wektorze warto≈õci **v<sup>(i)</sup>**, kt√≥ra determinuje rozmiar wynikowego wektora kontekstu, mo≈ºe byƒá dowolna. W dalszej czƒô≈õci przyk≈Çadu kodu przyjmujemy wiƒôc, ≈ºe $d_q = d_k = 24$ oraz $d_v = 28$, inicjalizujƒÖc macierze projekcji w nastƒôpujƒÖcy spos√≥b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539ae045",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d = embedded_sentence.shape[1]\n",
    "\n",
    "d_q, d_k, d_v = 24, 24, 28\n",
    "\n",
    "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
    "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
    "W_value = torch.nn.Parameter(torch.rand(d_v, d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d6fc381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_query: torch.Size([24, 16])\n",
      "W_key:   torch.Size([24, 16])\n",
      "W_value: torch.Size([28, 16])\n"
     ]
    }
   ],
   "source": [
    "print(\"W_query:\", W_query.shape)\n",
    "print(\"W_key:  \", W_key.shape)\n",
    "print(\"W_value:\", W_value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b99efd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24])\n",
      "torch.Size([24])\n",
      "torch.Size([28])\n"
     ]
    }
   ],
   "source": [
    "x_2 = embedded_sentence[1]\n",
    "query_2 = W_query.matmul(x_2)\n",
    "key_2 = W_key.matmul(x_2)\n",
    "value_2 = W_value.matmul(x_2)\n",
    "\n",
    "print(query_2.shape)\n",
    "print(key_2.shape)\n",
    "print(value_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fc074e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 24])\n",
      "values.shape: torch.Size([6, 28])\n"
     ]
    }
   ],
   "source": [
    "keys = W_key.matmul(embedded_sentence.T).T\n",
    "values = W_value.matmul(embedded_sentence.T).T\n",
    "\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8aba9",
   "metadata": {},
   "source": [
    "Jak pokazano na ilustracji powy≈ºej, obliczamy $ \\omega_{i,j} $ jako iloczyn skalarny pomiƒôdzy sekwencjami zapyta≈Ñ i kluczy:\n",
    "\n",
    "$$ \\omega_{i,j} = \\mathbf{q}^{(i)^\\top} \\mathbf{k}^{(j)} $$\n",
    "\n",
    "Na przyk≈Çad mo≈ºemy obliczyƒá nieznormalizowanƒÖ wagƒô atencji (attention weight) dla zapytania i piƒÖtego elementu wej≈õciowego (odpowiadajƒÖcego pozycji indeksu 4) w nastƒôpujƒÖcy spos√≥b:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a20060c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11.1466, grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "omega_24 = query_2.dot(keys[4])\n",
    "print(omega_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b97cc3",
   "metadata": {},
   "source": [
    "M√≥wi to nam jak bardzo token na pozycji 2 (czyli \"is\") jest powiƒÖzany z tokenem na pozycji 4 (czyli \"dessert\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3f4c9",
   "metadata": {},
   "source": [
    "Poniewa≈º bƒôdziemy potrzebowaƒá tych warto≈õci do obliczenia wag atencji w dalszej czƒô≈õci, obliczmy warto≈õci $ \\omega $ dla wszystkich token√≥w wej≈õciowych, tak jak pokazano na poprzedniej ilustracji:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "141ba5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 8.5808, -7.6597,  3.2558,  1.0395, 11.1466, -0.4800],\n",
      "       grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "omega_2 = query_2.matmul(keys.T)\n",
    "print(omega_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39448c",
   "metadata": {},
   "source": [
    "Skalowanie przez $d_k$ zapewnia, ≈ºe d≈Çugo≈õƒá euklidesowa wektor√≥w wag pozostaje w przybli≈ºeniu na tym samym poziomie. Pomaga to zapobiec sytuacji, w kt√≥rej wagi uwagi stajƒÖ siƒô zbyt ma≈Çe lub zbyt du≈ºe, co mog≈Çoby prowadziƒá do niestabilno≈õci numerycznej lub utrudniaƒá zbie≈ºno≈õƒá modelu podczas uczenia.\n",
    "\n",
    "W kodzie obliczanie wag uwagi mo≈ºna zaimplementowaƒá w nastƒôpujƒÖcy spos√≥b:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a74933f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2912, 0.0106, 0.0982, 0.0625, 0.4917, 0.0458],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "attention_weights_2 = F.softmax(omega_2 / d_k**0.5, dim=0)\n",
    "print(attention_weights_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd2510",
   "metadata": {},
   "source": [
    "Ostatecznym krokiem jest obliczenie wektora kontekstu $ \\mathbf{z}^{(2)} $, kt√≥ry stanowi wersjƒô naszego oryginalnego wektora zapytania $ \\mathbf{x}^{(2)} $, wa≈ºonƒÖ przez wagi uwagi. Wektor ten uwzglƒôdnia wszystkie pozosta≈Çe elementy wej≈õciowe jako kontekst poprzez wagi uwagi:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cb6f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28])\n",
      "tensor([-1.5993,  0.0156,  1.2670,  0.0032, -0.6460, -1.1407, -0.4908, -1.4632,\n",
      "         0.4747,  1.1926,  0.4506, -0.7110,  0.0602,  0.7125, -0.1628, -2.0184,\n",
      "         0.3838, -2.1188, -0.8136, -1.5694,  0.7934, -0.2911, -1.3640, -0.2366,\n",
      "        -0.9564, -0.5265,  0.0624,  1.7084], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "context_vector_2 = attention_weights_2.matmul(values)\n",
    "\n",
    "print(context_vector_2.shape)\n",
    "print(context_vector_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8b798",
   "metadata": {},
   "source": [
    "Zauwa≈º, ≈ºe ten wektor wyj≈õciowy ma wiƒôcej wymiar√≥w ($d_v = 28$) ni≈º oryginalny wektor wej≈õciowy ($d = 16$), poniewa≈º wcze≈õniej przyjƒôli≈õmy $d_v > d$. Wyb√≥r rozmiaru osadzenia (embeddingu) jest jednak arbitralny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1eb9e",
   "metadata": {},
   "source": [
    "### üß≠ Podsumowanie krok√≥w obliczania samo-uwagi (scaled dot-product attention)\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"context-vector.png\" alt=\"Wektor kontekstu\" width=\"600\"/>\n",
    "  <img src=\"single-head.png\" alt=\"Macierze QKV\" width=\"600\"/>\n",
    "</p>\n",
    "\n",
    "1. **Embedding** ‚Äì wej≈õciowe s≈Çowa (tokeny) zosta≈Çy zamienione na wektory o ustalonym rozmiarze $d$.  \n",
    "   Ka≈ºdy token w sekwencji ma wiƒôc reprezentacjƒô numerycznƒÖ $\\mathbf{x}^{(i)} \\in \\mathbb{R}^d$.\n",
    "\n",
    "2. **Projekcje na zapytania, klucze i warto≈õci** ‚Äì wektory osadze≈Ñ $\\mathbf{x}^{(i)}$ zosta≈Çy przekszta≈Çcone przy pomocy trzech macierzy wag:  \n",
    "   $$\n",
    "   \\mathbf{q}^{(i)} = \\mathbf{W}_q \\mathbf{x}^{(i)}, \\quad\n",
    "   \\mathbf{k}^{(i)} = \\mathbf{W}_k \\mathbf{x}^{(i)}, \\quad\n",
    "   \\mathbf{v}^{(i)} = \\mathbf{W}_v \\mathbf{x}^{(i)}\n",
    "   $$\n",
    "   gdzie $\\mathbf{W}_q$, $\\mathbf{W}_k$, $\\mathbf{W}_v$ majƒÖ odpowiednio wymiary $(d_q \\times d)$, $(d_k \\times d)$ i $(d_v \\times d)$.\n",
    "\n",
    "3. **Obliczenie surowych wag uwagi** ‚Äì dla ka≈ºdej pary token√≥w $(i, j)$ obliczono wsp√≥≈Çczynnik podobie≈Ñstwa (ang. *attention score*) jako iloczyn skalarny:  \n",
    "   $$\n",
    "   \\omega_{i,j} = \\mathbf{q}^{(i)^\\top} \\mathbf{k}^{(j)}\n",
    "   $$\n",
    "\n",
    "4. **Skalowanie przez $d_k$** ‚Äì warto≈õci $\\omega_{i,j}$ zosta≈Çy przeskalowane przez $\\sqrt{d_k}$, aby utrzymaƒá stabilnƒÖ wielko≈õƒá gradient√≥w i zapobiec zbyt du≈ºym lub ma≈Çym warto≈õciom uwagi.\n",
    "\n",
    "5. **Normalizacja (softmax)** ‚Äì przeskalowane wagi zosta≈Çy znormalizowane funkcjƒÖ softmax, tak aby ich suma dla ka≈ºdego zapytania wynosi≈Ça 1 (interpretacja jako rozk≈Çad prawdopodobie≈Ñstwa).\n",
    "\n",
    "6. **Obliczenie wektora kontekstu** ‚Äì dla ka≈ºdego tokena $i$ obliczono wektor kontekstu jako ≈õredniƒÖ wa≈ºonƒÖ wektor√≥w warto≈õci $\\mathbf{v}^{(j)}$ z wagami uwagi:  \n",
    "   $$\n",
    "   \\mathbf{z}^{(i)} = \\sum_j \\text{softmax}(\\omega_{i,j}) \\, \\mathbf{v}^{(j)}\n",
    "   $$\n",
    "\n",
    "7. **Interpretacja** ‚Äì otrzymany wektor $\\mathbf{z}^{(i)}$ jest nowƒÖ reprezentacjƒÖ tokena, kt√≥ra uwzglƒôdnia jego kontekst w ca≈Çej sekwencji (czyli ‚Äûna co token zwraca uwagƒô‚Äù).\n",
    "\n",
    "nasze przyk≈Çadowe zdanie:  \n",
    "**\"Life is short, eat dessert first\"**\n",
    "\n",
    "S≈Çownik token√≥w:  \n",
    "`{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}`\n",
    "\n",
    "| Symbol | Znaczenie | Typ danych | Rola | Przyk≈Çad (dla zdania *Life is short, eat dessert first*) |\n",
    "|:--|:--|:--|:--|:--|\n",
    "| **$\\mathbf{x}^{(i)}$** | wektor osadzenia (*embedding*) tokena wej≈õciowego | wektor $\\in \\mathbb{R}^d$ | ‚ÄûJak wyglƒÖda moje s≈Çowo w przestrzeni cech?‚Äù | wektor reprezentujƒÖcy znaczenie s≈Çowa **Life** w przestrzeni embedding√≥w |\n",
    "| **$\\mathbf{q}^{(i)}$** | wektor zapytania (*query*) | wektor $\\in \\mathbb{R}^{d_q}$ | ‚ÄûCzego szukam?‚Äù | wektor okre≈õlajƒÖcy, czego **Life** szuka w innych s≈Çowach zdania |\n",
    "| **$\\mathbf{k}^{(j)}$** | wektor klucza (*key*) | wektor $\\in \\mathbb{R}^{d_k}$ | ‚ÄûJakie mam cechy?‚Äù | wektor opisujƒÖcy cechy s≈Çowa **dessert**, kt√≥re mogƒÖ przyciƒÖgnƒÖƒá uwagƒô |\n",
    "| **$\\mathbf{v}^{(j)}$** | wektor warto≈õci (*value*) | wektor $\\in \\mathbb{R}^{d_v}$ | ‚ÄûJakƒÖ niosƒô informacjƒô?‚Äù | reprezentacja semantyczna s≈Çowa **dessert**, kt√≥ra mo≈ºe byƒá przekazana dalej |\n",
    "| **$\\omega_{i,j}$** | surowy wynik podobie≈Ñstwa | skalar | ‚ÄûNa ile podobni jeste≈õmy?‚Äù | warto≈õƒá okre≈õlajƒÖca podobie≈Ñstwo miƒôdzy **Life** a **dessert** |\n",
    "| **$\\alpha_{i,j}$** | waga uwagi (po softmaxie) | skalar | ‚ÄûJak bardzo siƒô liczƒô?‚Äù | waga okre≈õlajƒÖca, ile uwagi **Life** po≈õwiƒôca s≈Çowu **dessert** |\n",
    "| **$\\mathbf{z}^{(i)}$** | wektor kontekstu | wektor $\\in \\mathbb{R}^{d_v}$ | ‚ÄûNowa reprezentacja tokena *i*‚Äù | nowa reprezentacja **Life**, uwzglƒôdniajƒÖca kontekst ca≈Çego zdania |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49977ce",
   "metadata": {},
   "source": [
    "# Multi-Head Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a760fc15",
   "metadata": {},
   "source": [
    "Jak sama nazwa wskazuje, **multi-head attention** (uwaga wielog≈Çowa) obejmuje wiele takich g≈Ç√≥w ‚Äî ka≈ºda z nich sk≈Çada siƒô z w≈Çasnych macierzy **zapytania (query)**, **klucza (key)** oraz **warto≈õci (value)**.  \n",
    "Koncepcja ta jest analogiczna do wykorzystania wielu jƒÖder (*kernels*) w konwolucyjnych sieciach neuronowych (CNN).\n",
    "\n",
    "Aby zilustrowaƒá to w kodzie, za≈Ç√≥≈ºmy, ≈ºe mamy **3 g≈Çowy uwagi**.  \n",
    "W takim przypadku rozszerzamy macierze wag z wymiaru $d' \\times d$ do $3 \\times d' \\times d$, tak aby ka≈ºda g≈Çowa mia≈Ça sw√≥j w≈Çasny zestaw wag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f83f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 3\n",
    "multihead_W_query = torch.nn.Parameter(torch.rand(h, d_q, d))\n",
    "multihead_W_key = torch.nn.Parameter(torch.rand(h, d_k, d))\n",
    "multihead_W_value = torch.nn.Parameter(torch.rand(h, d_v, d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "727eece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 24])\n"
     ]
    }
   ],
   "source": [
    "multihead_query_2 = multihead_W_query.matmul(x_2)\n",
    "print(multihead_query_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3eccb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multihead_key_2 = multihead_W_key.matmul(x_2)\n",
    "multihead_value_2 = multihead_W_value.matmul(x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b74c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 6])\n"
     ]
    }
   ],
   "source": [
    "stacked_inputs = embedded_sentence.T.repeat(3, 1, 1)\n",
    "print(stacked_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08947f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihead_keys.shape: torch.Size([3, 24, 6])\n",
      "multihead_values.shape: torch.Size([3, 28, 6])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = torch.bmm(multihead_W_key, stacked_inputs)\n",
    "multihead_values = torch.bmm(multihead_W_value, stacked_inputs)\n",
    "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
    "print(\"multihead_values.shape:\", multihead_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1cc8b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multihead_keys.shape: torch.Size([3, 6, 24])\n",
      "multihead_values.shape: torch.Size([3, 6, 28])\n"
     ]
    }
   ],
   "source": [
    "multihead_keys = multihead_keys.permute(0, 2, 1)\n",
    "multihead_values = multihead_values.permute(0, 2, 1)\n",
    "print(\"multihead_keys.shape:\", multihead_keys.shape)\n",
    "print(\"multihead_values.shape:\", multihead_values.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf003f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
