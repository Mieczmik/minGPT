{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43769d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "import zipfile\n",
    " \n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tokenizers\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04e3cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.manythings.org/anki/pol-eng.zip\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/126.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "r.raise_for_status()\n",
    "\n",
    "with open(\"pol-eng.zip\", \"wb\") as f:\n",
    "    f.write(r.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5020fd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "url = \"https://www.manythings.org/anki/pol-eng.zip\"\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                  \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                  \"Chrome/126.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "r.raise_for_status()\n",
    "\n",
    "with open(\"pol-eng.zip\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4504e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize text\n",
    "# each line of the file is in the format \"<english>\\t<french>\"\n",
    "# We convert text to lowercase, normalize unicode (UFKC)\n",
    "def normalize(line):\n",
    "    \"\"\"Normalize a line of text and split into two at the tab character\"\"\"\n",
    "    line = unicodedata.normalize(\"NFKC\", line.strip().lower())\n",
    "    parts = line.split(\"\\t\")\n",
    "    if len(parts) < 2:\n",
    "        return None  # pomiń niepoprawne linie\n",
    "\n",
    "    # niektóre linie mają więcej niż jedno tłumaczenie – weź tylko pierwsze dwa\n",
    "    eng, pl = parts[0], parts[1]\n",
    "\n",
    "    return eng.strip(), pl.strip()\n",
    "\n",
    "text_pairs = []\n",
    "with zipfile.ZipFile(\"pol-eng.zip\", \"r\") as zip_ref:\n",
    "    for line in zip_ref.read(\"pol.txt\").decode(\"utf-8\").splitlines():\n",
    "        eng, pol = normalize(line)\n",
    "        text_pairs.append((eng, pol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1134d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    " \n",
    "if os.path.exists(\"en_tokenizer.json\") and os.path.exists(\"pl_tokenizer.json\"):\n",
    "    en_tokenizer = tokenizers.Tokenizer.from_file(\"en_tokenizer.json\")\n",
    "    pl_tokenizer = tokenizers.Tokenizer.from_file(\"pl_tokenizer.json\")\n",
    "else:\n",
    "    en_tokenizer = tokenizers.Tokenizer(tokenizers.models.BPE())\n",
    "    pl_tokenizer = tokenizers.Tokenizer(tokenizers.models.BPE())\n",
    " \n",
    "    # Configure pre-tokenizer to split on whitespace and punctuation, add space at beginning of the sentence\n",
    "    en_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    "    pl_tokenizer.pre_tokenizer = tokenizers.pre_tokenizers.ByteLevel(add_prefix_space=True)\n",
    " \n",
    "    # Configure decoder: So that word boundary symbol \"Ġ\" will be removed\n",
    "    en_tokenizer.decoder = tokenizers.decoders.ByteLevel()\n",
    "    pl_tokenizer.decoder = tokenizers.decoders.ByteLevel()\n",
    " \n",
    "    # Train BPE for English and French using the same trainer\n",
    "    VOCAB_SIZE = 8000\n",
    "    trainer = tokenizers.trainers.BpeTrainer(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        special_tokens=[\"[start]\", \"[end]\", \"[pad]\"],\n",
    "        show_progress=True\n",
    "    )\n",
    "    en_tokenizer.train_from_iterator([x[0] for x in text_pairs], trainer=trainer)\n",
    "    pl_tokenizer.train_from_iterator([x[1] for x in text_pairs], trainer=trainer)\n",
    " \n",
    "    en_tokenizer.enable_padding(pad_id=en_tokenizer.token_to_id(\"[pad]\"), pad_token=\"[pad]\")\n",
    "    pl_tokenizer.enable_padding(pad_id=pl_tokenizer.token_to_id(\"[pad]\"), pad_token=\"[pad]\")\n",
    " \n",
    "    # Save the trained tokenizers\n",
    "    en_tokenizer.save(\"en_tokenizer.json\", pretty=True)\n",
    "    pl_tokenizer.save(\"pl_tokenizer.json\", pretty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7cc9a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "    x1, x2 = x.chunk(2, dim=-1)\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    return (x * cos) + (rotate_half(x) * sin)\n",
    "\n",
    "class RotaryPositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=1024):\n",
    "        super().__init__()\n",
    "        N = 10000\n",
    "        inv_freq = 1. / (N ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        position = torch.arange(max_seq_len).float()\n",
    "        inv_freq = torch.cat((inv_freq, inv_freq), dim=-1)\n",
    "        sinusoid_inp = torch.outer(position, inv_freq)\n",
    "        self.register_buffer(\"cos\", sinusoid_inp.cos())\n",
    "        self.register_buffer(\"sin\", sinusoid_inp.sin())\n",
    "\n",
    "    def forward(self, x, seq_len=None):\n",
    "        if seq_len is None:\n",
    "            seq_len = x.size(1)\n",
    "        cos = self.cos[:seq_len].view(1, seq_len, 1, -1)\n",
    "        sin = self.sin[:seq_len].view(1, seq_len, 1, -1)\n",
    "        return apply_rotary_pos_emb(x, cos, sin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1a14933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GQA(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, num_kv_heads=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_heads = num_kv_heads or num_heads\n",
    "        self.head_dim = hidden_dim // num_heads\n",
    "        self.num_groups = num_heads // num_kv_heads\n",
    "        self.dropout = dropout\n",
    "        self.q_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.k_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.v_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.out_proj = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None, rope=None):\n",
    "        q_batch_size, q_seq_len, hidden_dim = q.shape\n",
    "        k_batch_size, k_seq_len, hidden_dim = k.shape\n",
    "        v_batch_size, v_seq_len, hidden_dim = v.shape\n",
    "\n",
    "        # projection\n",
    "        q = self.q_proj(q).view(q_batch_size, q_seq_len, -1, self.head_dim).transpose(1, 2)\n",
    "        k = self.k_proj(k).view(k_batch_size, k_seq_len, -1, self.head_dim).transpose(1, 2)\n",
    "        v = self.v_proj(v).view(v_batch_size, v_seq_len, -1, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # apply rotary positional encoding\n",
    "        if rope:\n",
    "            q = rope(q)\n",
    "            k = rope(k)\n",
    "\n",
    "        # compute grouped query attention\n",
    "        q = q.contiguous()\n",
    "        k = k.contiguous()\n",
    "        v = v.contiguous()\n",
    "        output = F.scaled_dot_product_attention(q, k, v,\n",
    "                                                attn_mask=mask,\n",
    "                                                dropout_p=self.dropout,\n",
    "                                                enable_gqa=True)\n",
    "        output = output.transpose(1, 2).reshape(q_batch_size, q_seq_len, hidden_dim).contiguous()\n",
    "        output = self.out_proj(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b1a8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwiGLU(nn.Module):\n",
    "    def __init__(self, hidden_dim, intermediate_dim):\n",
    "        super().__init__()\n",
    "        self.gate = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.up = nn.Linear(hidden_dim, intermediate_dim)\n",
    "        self.down = nn.Linear(intermediate_dim, hidden_dim)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.act(self.gate(x)) * self.up(x)\n",
    "        x = self.down(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "922feaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, num_kv_heads=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n",
    "        self.mlp = SwiGLU(hidden_dim, 4 * hidden_dim)\n",
    "        self.norm1 = nn.RMSNorm(hidden_dim)\n",
    "        self.norm2 = nn.RMSNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, mask=None, rope=None):\n",
    "        # self-attention sublayer\n",
    "        out = x\n",
    "        out = self.norm1(x)\n",
    "        out = self.self_attn(out, out, out, mask, rope)\n",
    "        x = out + x\n",
    "        # MLP sublayer\n",
    "        out = self.norm2(x)\n",
    "        out = self.mlp(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd767d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim, num_heads, num_kv_heads=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n",
    "        self.cross_attn = GQA(hidden_dim, num_heads, num_kv_heads, dropout)\n",
    "        self.mlp = SwiGLU(hidden_dim, 4 * hidden_dim)\n",
    "        self.norm1 = nn.RMSNorm(hidden_dim)\n",
    "        self.norm2 = nn.RMSNorm(hidden_dim)\n",
    "        self.norm3 = nn.RMSNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, enc_out, mask=None, rope=None):\n",
    "        # self-attention sublayer\n",
    "        out = x\n",
    "        out = self.norm1(out)\n",
    "        out = self.self_attn(out, out, out, mask, rope)\n",
    "        x = out + x\n",
    "        # cross-attention sublayer\n",
    "        out = self.norm2(x)\n",
    "        out = self.cross_attn(out, enc_out, enc_out, None, rope)\n",
    "        x = out + x\n",
    "        # MLP sublayer\n",
    "        x = out + x\n",
    "        out = self.norm3(x)\n",
    "        out = self.mlp(out)\n",
    "        return out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "640d4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_layers, num_heads, num_kv_heads, hidden_dim,\n",
    "                 max_seq_len, vocab_size_src, vocab_size_tgt, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.rope = RotaryPositionalEncoding(hidden_dim // num_heads, max_seq_len)\n",
    "        self.src_embedding = nn.Embedding(vocab_size_src, hidden_dim)\n",
    "        self.tgt_embedding = nn.Embedding(vocab_size_tgt, hidden_dim)\n",
    "        self.encoders = nn.ModuleList([\n",
    "            EncoderLayer(hidden_dim, num_heads, num_kv_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoders = nn.ModuleList([\n",
    "            DecoderLayer(hidden_dim, num_heads, num_kv_heads, dropout) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.out = nn.Linear(hidden_dim, vocab_size_tgt)\n",
    "\n",
    "    def forward(self, src_ids, tgt_ids, src_mask=None, tgt_mask=None):\n",
    "        # Encoder\n",
    "        x = self.src_embedding(src_ids)\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, src_mask, self.rope)\n",
    "        enc_out = x\n",
    "        # Decoder\n",
    "        x = self.tgt_embedding(tgt_ids)\n",
    "        for decoder in self.decoders:\n",
    "            x = decoder(x, enc_out, tgt_mask, self.rope)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c824df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"num_layers\": 4,\n",
    "    \"num_heads\": 8,\n",
    "    \"num_kv_heads\": 4,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"max_seq_len\": 768,\n",
    "    \"vocab_size_src\": len(en_tokenizer.get_vocab()),\n",
    "    \"vocab_size_tgt\": len(pl_tokenizer.get_vocab()),\n",
    "    \"dropout\": 0.1,\n",
    "}\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Transformer(**model_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "111b214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TranslationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_pairs):\n",
    "        self.text_pairs = text_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eng, pol = self.text_pairs[idx]\n",
    "        return eng, \"[start] \" + pol + \" [end]\"\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    en_str, pl_str = zip(*batch)\n",
    "    en_enc = en_tokenizer.encode_batch(en_str, add_special_tokens=True)\n",
    "    pl_enc = pl_tokenizer.encode_batch(pl_str, add_special_tokens=True)\n",
    "    en_ids = [enc.ids for enc in en_enc]\n",
    "    pl_ids = [enc.ids for enc in pl_enc]\n",
    "    return torch.tensor(en_ids), torch.tensor(pl_ids)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "dataset = TranslationDataset(text_pairs)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c71585c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: tensor([[ 261,  286,   74, 2352,  127,   24,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  168,  111,  147,  105,  113,   11,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  93,  273,  796,  239, 2080,  153, 3421,   11,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 243,  121,   75, 4655,  305,  232,   24,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 114,  387,   92,  406,   11,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 113,  121,   64, 1164, 2778,   11,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  80, 1343,   92,  320,  372,  114,   93,  121, 5094,   65,  105,  114,\n",
      "          681,   11,    2,    2,    2],\n",
      "        [ 812,  637,  127,   11,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  142,   92,  178,  431,   11,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 111,  214,  482,  258,  128,  164,  532,   11,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 111,  184, 1642,  227, 1009,  603,   11,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  161,  139, 1949,   11,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  93, 7331,  937,   75, 1664, 1268,  654,  189,  661,   11,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 219,   92,   74,  795,  150,   61,  393,   24,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 113,  121, 3860,   11,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 142,   92,  417,  431,  798, 1172,   11,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 231,  680, 3338,  187, 1009,  603,  139,   75,  597,  203,  262, 1215,\n",
      "         7988,  128,  729,  649,   11],\n",
      "        [ 314,  127,  150,   74,  184, 1172,   11,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  161,  170,  257,   65,  287,  114,   11,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  93, 5685,   65,  119,  122, 3658,  112, 5478,   11,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 150,  121,  164,  913, 4456,  112,  781,   24,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  785,   65,  652,   80,   11,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 237,   74,  358, 3906,   24,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 182, 4458,  140, 2778,   11,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  80,  147,   92,  581,  113,   11,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  80,  354,  383,  595,  193,  329,   11,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  161, 3315,   11,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  142,   92,  210,   61,  265,  576,  105,  138,  464,   11,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  74, 2455,  138,   11,    2,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 113,  574,   92,  446, 1815,   11,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [  61,  382,   64,  788,   11,    2,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2],\n",
      "        [ 286,  111,  496,  146,   80,  232,   24,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2]])\n",
      "French: tensor([[   0,  406, 6933,  214, 3645,  484,   27,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  383,   11,  127, 5900, 2193,   85,  331,   13,   63,    1,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  290,   93,  528,  797, 3529, 1974, 2730,  442, 7179, 3493,   13,\n",
      "           63,    1,    2,    2,    2,    2,    2],\n",
      "        [   0,  303,  271,  111, 2860,  181,   27,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   85,  470, 2084,   13,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   85, 4335, 7781,   13,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  419,  434,   93, 4771,   11,  127,  111,   84,  394,  284,   99,\n",
      "         1163,  134,   85,  331,   13,   63,    1],\n",
      "        [   0,  604,  214,   93,  924,   13,   63,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  470,  155,  118,   93, 1086,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   93, 1288, 2459, 5891,   83, 3082,   13,   63,    1,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 1343,  775,  380,  119, 1542,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  232,  112, 7859,   13,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 6598, 3491,  112, 3030,  122, 6053,   83, 1243,   13,   63,    1,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   93, 1628,  458,   11,  159, 1206,   27,   63,    1,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  340, 1368,   13,   63,    1,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   93, 1411,  470,   11, 1420,  720,  368,  101,   13,   63,    1,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 1718,  782,  118,  187,  998,   83, 5563, 1214, 2423,  194,  148,\n",
      "         3940, 1922, 1479,  631,   13,   63,    1],\n",
      "        [   0, 1139,   11,  108,  992,  862,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   93,  616,  236, 4311,   13,   63,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 3038,  777,   11,  127,  111, 7286,   83, 4317,   42, 5370,   13,\n",
      "           63,    1,    2,    2,    2,    2,    2],\n",
      "        [   0,  673,  111,  626, 1535, 6437,   83, 1802,   27,   63,    1,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 2205, 1276,  253,   13,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  457,  155, 2683,   27,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 2981, 3703, 1326, 3548,   13,   63,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   98,   93,  269,  236, 2451,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   98, 1681,  122, 1065, 1756,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  232,  112,  537,   13,   63,    1,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  444,   11,  127,  335,  359,   93,  616,  423, 1224,  236,  331,\n",
      "           13,   63,    1,    2,    2,    2,    2],\n",
      "        [   0,  188,   85, 3305, 1874,   13,   63,    1,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,   85,   93,  540, 2122, 1795,   13,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0,  232, 2013,   13,   63,    1,    2,    2,    2,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2],\n",
      "        [   0, 1226,  547, 3014,  112,  253,   27,   63,    1,    2,    2,    2,\n",
      "            2,    2,    2,    2,    2,    2,    2]])\n"
     ]
    }
   ],
   "source": [
    "for en_ids, pl_ids in dataloader:\n",
    "    print(f\"English: {en_ids}\")\n",
    "    print(f\"French: {pl_ids}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "931ca490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_causal_mask(seq_len, device):\n",
    "    mask = torch.triu(torch.full((seq_len, seq_len), float('-inf'), device=device), diagonal=1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e46b877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(batch, padding_token_id):\n",
    "    batch_size, seq_len = batch.shape\n",
    "    device = batch.device\n",
    "    padded = torch.zeros_like(batch, device=device).float().masked_fill(batch == padding_token_id, float('-inf'))\n",
    "    mask = torch.zeros(batch_size, seq_len, seq_len, device=device) + padded[:,:,None] + padded[:,None,:]\n",
    "    return mask[:, None, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba3bb321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machineblue/repositories/translator/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:243: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60; Avg loss 4.096698644128886; Latest loss 3.0250887870788574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 2.8337806796175045\n",
      "Epoch 2/60; Avg loss 2.788626352309005; Latest loss 2.6558470726013184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 2.1281219177710584\n",
      "Epoch 3/60; Avg loss 2.289740744560185; Latest loss 2.501023530960083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.8111035327729108\n",
      "Epoch 4/60; Avg loss 1.9999193435238558; Latest loss 2.5427656173706055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.5360182169847807\n",
      "Epoch 5/60; Avg loss 1.7943998007827269; Latest loss 1.8478368520736694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.3832164406041476\n",
      "Epoch 6/60; Avg loss 1.6288506450400253; Latest loss 1.8708763122558594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.2374786511155444\n",
      "Epoch 7/60; Avg loss 1.4774724625776787; Latest loss 1.6931941509246826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.1248808801909116\n",
      "Epoch 8/60; Avg loss 1.3545997662035663; Latest loss 1.6242321729660034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 1.0742572821612422\n",
      "Epoch 9/60; Avg loss 1.2462908121425331; Latest loss 1.088580846786499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.9992654616823914\n",
      "Epoch 10/60; Avg loss 1.1521053031619761; Latest loss 1.2594029903411865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.9367452514083406\n",
      "Epoch 11/60; Avg loss 1.0866035470318707; Latest loss 1.6371737718582153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.8501602898911101\n",
      "Epoch 12/60; Avg loss 1.0295887278202283; Latest loss 1.3390588760375977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.8296748725685914\n",
      "Epoch 13/60; Avg loss 1.0087333970166898; Latest loss 1.283947229385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.8488006032865527\n",
      "Epoch 14/60; Avg loss 0.9580731604308; Latest loss 1.2222539186477661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.7968495941448741\n",
      "Epoch 15/60; Avg loss 0.9069944125876914; Latest loss 1.189395546913147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.6963220210941152\n",
      "Epoch 16/60; Avg loss 0.8531025157720035; Latest loss 0.7798734903335571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.6940147786156611\n",
      "Epoch 17/60; Avg loss 0.8021865700786123; Latest loss 0.9306039810180664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.5992186551984817\n",
      "Epoch 18/60; Avg loss 0.7541010420213645; Latest loss 0.776816725730896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.5584236017064307\n",
      "Epoch 19/60; Avg loss 0.7034157690593259; Latest loss 0.843147337436676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.5554019195451395\n",
      "Epoch 20/60; Avg loss 0.6643437010990559; Latest loss 0.5714995861053467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.5245650897006954\n",
      "Epoch 21/60; Avg loss 0.6192800577743721; Latest loss 0.6121620535850525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.47248147761520415\n",
      "Epoch 22/60; Avg loss 0.5773843680812751; Latest loss 0.7021769881248474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.46768921340842134\n",
      "Epoch 23/60; Avg loss 0.538996307572072; Latest loss 0.6130213141441345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.45883150038604525\n",
      "Epoch 24/60; Avg loss 0.504644463594392; Latest loss 0.6355393528938293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.40750095187588775\n",
      "Epoch 25/60; Avg loss 0.4751349442010302; Latest loss 0.658591628074646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.37189820975653193\n",
      "Epoch 26/60; Avg loss 0.4405467912609862; Latest loss 0.5668201446533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.33505229517799123\n",
      "Epoch 27/60; Avg loss 0.4164567585441981; Latest loss 0.6039367914199829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.3402984551855727\n",
      "Epoch 28/60; Avg loss 0.39434592704186455; Latest loss 0.6600249409675598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.3062501291384973\n",
      "Epoch 29/60; Avg loss 0.364822095092363; Latest loss 0.3183078169822693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.28139396769749103\n",
      "Epoch 30/60; Avg loss 0.33754022480086243; Latest loss 0.7558216452598572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.26100009169461696\n",
      "Epoch 31/60; Avg loss 0.3144687582060015; Latest loss 0.3184591233730316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.24360140074049058\n",
      "Epoch 32/60; Avg loss 0.2869799555349365; Latest loss 0.30393359065055847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.2249272644712731\n",
      "Epoch 33/60; Avg loss 0.26516515095563176; Latest loss 0.24410958588123322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.21952540115550914\n",
      "Epoch 34/60; Avg loss 0.24535300271670563; Latest loss 0.18771925568580627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.2150392374471657\n",
      "Epoch 35/60; Avg loss 0.23404450048996842; Latest loss 0.34812915325164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.17556117159462592\n",
      "Epoch 36/60; Avg loss 0.20910632311746608; Latest loss 0.1159706711769104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.17560243716121235\n",
      "Epoch 37/60; Avg loss 0.20041046417909691; Latest loss 0.42961224913597107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.15469145014395183\n",
      "Epoch 38/60; Avg loss 0.18037113707177296; Latest loss 0.2432195544242859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.13748216278547865\n",
      "Epoch 39/60; Avg loss 0.16222046116773503; Latest loss 0.14209596812725067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.13211829097466096\n",
      "Epoch 40/60; Avg loss 0.15025901100592534; Latest loss 0.11331888288259506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.11422492249762012\n",
      "Epoch 41/60; Avg loss 0.13644030034707447; Latest loss 0.18769453465938568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.10588729173477864\n",
      "Epoch 42/60; Avg loss 0.12541529278554545; Latest loss 0.2878486216068268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.09353603049997888\n",
      "Epoch 43/60; Avg loss 0.114422532876795; Latest loss 0.057775065302848816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.0901099546041923\n",
      "Epoch 44/60; Avg loss 0.10552363240753752; Latest loss 0.19279521703720093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.08391413144978584\n",
      "Epoch 45/60; Avg loss 0.0954700652659215; Latest loss 0.12453530728816986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.0759484096040947\n",
      "Epoch 46/60; Avg loss 0.08757146469026841; Latest loss 0.0896192267537117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.06742265241785589\n",
      "Epoch 47/60; Avg loss 0.08056822297095555; Latest loss 0.025572726503014565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.06169689109183747\n",
      "Epoch 48/60; Avg loss 0.07317174340480004; Latest loss 0.11764517426490784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.05825147658222471\n",
      "Epoch 49/60; Avg loss 0.06772384938523265; Latest loss 0.1727825552225113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.05506358880081137\n",
      "Epoch 50/60; Avg loss 0.06165326463687894; Latest loss 0.019851485267281532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.04897872859763691\n",
      "Epoch 51/60; Avg loss 0.05755186770582151; Latest loss 0.05499405413866043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.045393065728864986\n",
      "Epoch 52/60; Avg loss 0.05193503073482107; Latest loss 0.0427817665040493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.041708463221861905\n",
      "Epoch 53/60; Avg loss 0.0480362647735547; Latest loss 0.0884770080447197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.039633023814710476\n",
      "Epoch 54/60; Avg loss 0.044817577740900984; Latest loss 0.0705394372344017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.03692043560635156\n",
      "Epoch 55/60; Avg loss 0.04154791339684126; Latest loss 0.04127172380685806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.036458278581862937\n",
      "Epoch 56/60; Avg loss 0.039173656615799544; Latest loss 0.012574691325426102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 116.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.034782544891039914\n",
      "Epoch 57/60; Avg loss 0.037184714837776064; Latest loss 0.06925081461668015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.034217104987263144\n",
      "Epoch 58/60; Avg loss 0.03531523812051206; Latest loss 0.025644326582551003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.03411191303263454\n",
      "Epoch 59/60; Avg loss 0.034735216888623216; Latest loss 0.006583702750504017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 117.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.033753974537184844\n",
      "Epoch 60/60; Avg loss 0.033859962240922574; Latest loss 0.03819034621119499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1622/1622 [00:13<00:00, 118.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval loss: 0.03395433518871936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 60\n",
    "LR = 0.005\n",
    "WARMUP_STEPS = 1000\n",
    "CLIP_NORM = 5.0\n",
    "best_loss = float('inf')\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=pl_tokenizer.token_to_id(\"[pad]\"))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "warmup_scheduler = optim.lr_scheduler.LinearLR(\n",
    "    optimizer, start_factor=0.01, end_factor=1.0, total_iters=WARMUP_STEPS)\n",
    "cosine_scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, T_max=N_EPOCHS * len(dataloader) - WARMUP_STEPS, eta_min=0)\n",
    "scheduler = optim.lr_scheduler.SequentialLR(\n",
    "    optimizer, schedulers=[warmup_scheduler, cosine_scheduler], milestones=[WARMUP_STEPS])\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for en_ids, pl_ids in dataloader:\n",
    "        # Move the \"sentences\" to device\n",
    "        en_ids = en_ids.to(device)\n",
    "        pl_ids = pl_ids.to(device)\n",
    "        # create source mask as padding mask, target mask as causal mask\n",
    "        src_mask = create_padding_mask(en_ids, en_tokenizer.token_to_id(\"[pad]\"))\n",
    "        tgt_mask = create_causal_mask(pl_ids.shape[1], device).unsqueeze(0)\n",
    "        tgt_mask = tgt_mask + create_padding_mask(pl_ids, pl_tokenizer.token_to_id(\"[pad]\"))\n",
    "        # zero the grad, then forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(en_ids, pl_ids, src_mask, tgt_mask)\n",
    "        # compute the loss: compare 3D logits to 2D targets\n",
    "        loss = loss_fn(outputs[:, :-1, :].reshape(-1, outputs.shape[-1]), pl_ids[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_NORM, error_if_nonfinite=False)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{N_EPOCHS}; Avg loss {epoch_loss/len(dataloader)}; Latest loss {loss.item()}\")\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for en_ids, pl_ids in tqdm.tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            en_ids = en_ids.to(device)\n",
    "            pl_ids = pl_ids.to(device)\n",
    "            src_mask = create_padding_mask(en_ids, en_tokenizer.token_to_id(\"[pad]\"))\n",
    "            tgt_mask = create_causal_mask(pl_ids.shape[1], device).unsqueeze(0) + create_padding_mask(pl_ids, pl_tokenizer.token_to_id(\"[pad]\"))\n",
    "            outputs = model(en_ids, pl_ids, src_mask, tgt_mask)\n",
    "            loss = loss_fn(outputs[:, :-1, :].reshape(-1, outputs.shape[-1]), pl_ids[:, 1:].reshape(-1))\n",
    "            epoch_loss += loss.item()\n",
    "    print(f\"Eval loss: {epoch_loss/len(dataloader)}\")\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), f\"transformer-epoch-{epoch+1}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4374bedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English: i'm saving money in order to study abroad.\n",
      "Polish: oszczędzam pieniądze na studia za granicą.\n",
      "Predicted:  oszczędzam pieniądze na studia za granicą. \n",
      "\n",
      "English: you're too young to get married, aren't you?\n",
      "Polish: jesteś za młoda żeby wyjść za mąż, nieprawdaż?\n",
      "Predicted:  jesteś za młoda żeby wyjść za mąż, nieprawdaż? \n",
      "\n",
      "English: what's your favorite swear word?\n",
      "Polish: jakie jest twoje ulubione przekleństwo?\n",
      "Predicted:  co jest ukratne coś do pożyte? \n",
      "\n",
      "English: we've got so much to talk about.\n",
      "Polish: mamy sporo do pogadania.\n",
      "Predicted:  mamy sporo do pogadania. \n",
      "\n",
      "English: i just don't want to have people thinking i'm weak.\n",
      "Polish: po prostu nie chcę, aby ludzie myśleli, że jestem słaby.\n",
      "Predicted:  po prostu nie chcę, aby ludzie myśleli, że jestem słaby. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test for a few samples\n",
    "model.eval()\n",
    "N_SAMPLES = 5\n",
    "MAX_LEN = 60\n",
    "with torch.no_grad():\n",
    "    start_token = torch.tensor([pl_tokenizer.token_to_id(\"[start]\")]).to(device)\n",
    "    for en, true_fr in random.sample(dataset.text_pairs, N_SAMPLES):\n",
    "        en_ids = torch.tensor(en_tokenizer.encode(en).ids).unsqueeze(0).to(device)\n",
    "\n",
    "        # get context from encoder\n",
    "        src_mask = create_padding_mask(en_ids, en_tokenizer.token_to_id(\"[pad]\"))\n",
    "        x = model.src_embedding(en_ids)\n",
    "        for encoder in model.encoders:\n",
    "            x = encoder(x, src_mask, model.rope)\n",
    "        enc_out = x\n",
    "\n",
    "        # generate output from decoder\n",
    "        pl_ids = start_token.unsqueeze(0)\n",
    "        for _ in range(MAX_LEN):\n",
    "            tgt_mask = create_causal_mask(pl_ids.shape[1], device).unsqueeze(0)\n",
    "            tgt_mask = tgt_mask + create_padding_mask(pl_ids, pl_tokenizer.token_to_id(\"[pad]\"))\n",
    "            x = model.tgt_embedding(pl_ids)\n",
    "            for decoder in model.decoders:\n",
    "                x = decoder(x, enc_out, tgt_mask, model.rope)\n",
    "            outputs = model.out(x)\n",
    "\n",
    "            outputs = outputs.argmax(dim=-1)\n",
    "            pl_ids = torch.cat([pl_ids, outputs[:, -1:]], axis=-1)\n",
    "            if pl_ids[0, -1] == pl_tokenizer.token_to_id(\"[end]\"):\n",
    "                break\n",
    "\n",
    "        # Decode the predicted IDs\n",
    "        pred_fr = pl_tokenizer.decode(pl_ids[0].tolist())\n",
    "        print(f\"English: {en}\")\n",
    "        print(f\"Polish: {true_fr}\")\n",
    "        print(f\"Predicted: {pred_fr}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e2692",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
